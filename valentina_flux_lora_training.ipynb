{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# FLUX.1-Dev LoRA Training for Valentina\nThis notebook follows the instructions from `agents.md` to train a facial identity LoRA in Google Colab using FLUX.1-Dev."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Clone FluxGym and sd-scripts\nRun the following commands to download the required repositories."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "!git clone https://github.com/TheLocalLab/fluxgym-Colab.git\n%cd /content/fluxgym-Colab/\n!git clone -b sd3 https://github.com/kohya-ss/sd-scripts"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Install dependencies\nInstall packages for both repositories and the nightly build of PyTorch."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "%cd /content/fluxgym-Colab/sd-scripts\n!pip install -r requirements.txt\n%cd /content/fluxgym-Colab/\n!pip install -r requirements.txt\n!pip install --pre torch==2.4.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Download FLUX.1-Dev components\nCreate the model folders and fetch the UNet, CLIP, T5 and VAE files."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "!mkdir -p /content/fluxgym-Colab/models/unet\n!mkdir -p /content/fluxgym-Colab/models/clip\n!mkdir -p /content/fluxgym-Colab/models/vae\n!wget -O /content/fluxgym-Colab/models/unet/flux1-dev-fp8.safetensors     https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-dev-fp8.safetensors\n!wget -O /content/fluxgym-Colab/models/clip/clip_l.safetensors     https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors?download=true\n!wget -O /content/fluxgym-Colab/models/clip/t5xxl_fp8.safetensors     https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors?download=true\n!wget -O /content/fluxgym-Colab/models/vae/ae.sft     https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/ae.sft?download=true"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Launch FluxGym\nThis command starts the Gradio interface where you will configure and train the LoRA."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "%cd /content/fluxgym-Colab\n!python app.py"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "After opening the public URL, upload your 18 PNG images (1024x1024) in the Dataset section, set the LoRA information (name, trigger word, hyperparameters) and start training from the Training tab."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Optional: Generate images with ComfyUI\nOnce training finishes and the LoRA file is saved, you can install ComfyUI to test generations."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "!git clone https://github.com/comfyanonymous/ComfyUI.git /content/ComfyUI\n%cd /content/ComfyUI\n!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121\n%cd custom_nodes\n!git clone https://github.com/city96/ComfyUI-GGUF.git\n%cd ComfyUI-GGUF\n!pip install -r requirements.txt"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Copy the Flux model files and your trained LoRA into the ComfyUI `models` directories, then run:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "%cd /content/ComfyUI\n!python main.py"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
