{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento de LoRA no FLUX.1-Dev\n",
    "Este notebook configura o ambiente no Google Colab (GPU A100), instala dependências e roda o **FluxGym** para treinar um LoRA de identidade facial (18 imagens 1024×1024)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração do ambiente\n",
    "Ative a GPU A100 em `Runtime > Change runtime type` e selecione **GPU** com **High-RAM** (conta Pro/Pro+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clone dos repositórios FluxGym e sd-scripts\n",
    "!git clone https://github.com/TheLocalLab/fluxgym-Colab.git\n",
    "%cd /content/fluxgym-Colab/\n",
    "!git clone -b sd3 https://github.com/kohya-ss/sd-scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instalação das dependências\n",
    "%cd /content/fluxgym-Colab/sd-scripts\n",
    "!pip install -r requirements.txt\n",
    "%cd /content/fluxgym-Colab/\n",
    "!pip install -r requirements.txt\n",
    "!pip install --pre torch==2.4.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dos componentes do FLUX.1-Dev\n",
    "!mkdir -p /content/fluxgym-Colab/models/unet\n",
    "!mkdir -p /content/fluxgym-Colab/models/clip\n",
    "!mkdir -p /content/fluxgym-Colab/models/vae\n",
    "!wget -O /content/fluxgym-Colab/models/unet/flux1-dev-fp8.safetensors \\\n         https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-dev-fp8.safetensors\n",
    "!wget -O /content/fluxgym-Colab/models/clip/clip_l.safetensors \\\n         https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors?download=true\n",
    "!wget -O /content/fluxgym-Colab/models/clip/t5xxl_fp8.safetensors \\\n         https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors?download=true\n",
    "!wget -O /content/fluxgym-Colab/models/vae/ae.sft \\\n         https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/ae.sft?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicie o FluxGym\n",
    "!python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação do dataset\n",
    "Envie 18 imagens PNG 1024×1024 do rosto de Valentina e crie legendas contendo a trigger word (ex. `valentinaface`).\n",
    "Na interface do FluxGym, faça upload das imagens e insira suas legendas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Treinamento\n",
    "Na seção **LoRA Info** defina: Repeat 10, Epochs 10 (~1800 passos), Learning rate 1e-4, Network Rank 16 (ou 32) e batch size 2.\n",
    "Clique em **Start Training** para iniciar. O progresso aparecerá no log. Ao final, o arquivo `.safetensors` estará em `outputs/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Uso do LoRA\n",
    "Copie o arquivo de saída para seu drive ou baixe localmente. Para gerar imagens, use o ComfyUI ou outra interface compatível com o FLUX.1-Dev e aplique este LoRA no modelo base."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
